{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d666ee0a-b908-4397-b851-cb2e1b18afd1",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083e4ab-9ad4-440d-99ce-d70d5939f3bd",
   "metadata": {},
   "source": [
    "Supervised learning models make predictions. They come in two varieties:\n",
    "1. Regression models - Predict a numeric outcome such as the price of a house\n",
    "2. Classification models - Predict a class or category from a finite set of classes such as whether a credit card transaction is legitimate or fradulent. If the model predicts between two categories it is called binary classification, if the model predicts between more than two possible outcomes it is called multiclass classification\n",
    "\n",
    "There are many supervised learning algorithms. They go by names such as linear regression, random forests, gradient-boosting machines (GBMs) and support vector machines (SVMs). Many but not all can be used both for regression and classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e616304-0865-48cc-bb1e-fe85b3bfb753",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccec973-918c-4df7-a290-7d3a3bebe0ce",
   "metadata": {},
   "source": [
    "One of the simplest supervised learning algorithms is KNN (k-Nearest Neighbors). The idea behind it is that given a set of data points you can predict a label for a new point by examining the points nearest it. For example in a regression problem in which each data point is characterized by x and y coordinates, this measn that given an x you can predict a y by finding n points with the nearest x values and averaging their ys. For a classification problem the class is determined by the highest cocurrence. In the real world ther is usually more than one feature column so not just x but x1, x2, x3, and so on. There are different ways to measure distances in n-dimensional space including Eucledian distance, Manhattan distance and Minkowski distance. You can even use weights so that nearby points contribute more to the outcome than faraway points. And rather than find the n nearest neighbors you can select all the neighbors within a given radius, a technique called radius neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772edfa0-e3b0-47c6-99bc-cf29bf54eed3",
   "metadata": {},
   "source": [
    "### Using K-Nearest Neighbors to classify flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a684964-7e37-4dc1-b28c-be958ad02d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "      <th>class name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   class class name  \n",
       "0      0     setosa  \n",
       "1      0     setosa  \n",
       "2      0     setosa  \n",
       "3      0     setosa  \n",
       "4      0     setosa  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['class'] = iris.target\n",
    "df['class name'] = iris.target_names[iris['target']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da480d2-8c4c-4714-a66d-d240933df2bf",
   "metadata": {},
   "source": [
    "Splitting the data into two datasets: one for training and one for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b975dce-d165-437c-b4fa-966d2a8df702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412356ac-963f-4fe4-bd28-5258bbdee65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9557aada-c67e-4282-9c46-4fe7bd71be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_sample = [[5.6, 4.4, 1.2, 0.4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752f47fd-e507-41a4-9e1a-ffa080e4c775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(iris_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7227aff-8d66-4559-967a-58e641cdccc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=10)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
